import torch
import torch.nn as nn
import torch.nn.functional as F
import gymnasium as gym
from gymnasium import spaces
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
import numpy as np
import re
import yaml
# å‡è®¾æ‚¨å·²ç»æœ‰äº†è¿™äº›è¾…åŠ©å‡½æ•°å’Œç±»
from AcAdjoint import AcAdjointFunction
from AcSimulation import AcSimulationCuDSS, AcSimulationPardiso
from Circuit import Circuit, BranchType
from build_ckt import build_ac_ckt



class CustomCombinedExtractorForDQN(BaseFeaturesExtractor):
    def __init__(self, observation_space: spaces.Dict, hidden_dim: int = 256):
        
        # --- æ­¥éª¤ 1: é¢„è®¡ç®—ç‰¹å¾ç»´åº¦ (åœ¨è°ƒç”¨ super ä¹‹å‰) ---
        # æˆ‘ä»¬å¯ä»¥å…ˆå®šä¹‰ç½‘ç»œç»“æ„ï¼Œä½†ä¸æŠŠå®ƒèµ‹ç»™ self
        
        canvas_size = 256
        
        # å…ˆä¸´æ—¶åˆ›å»ºä¸€ä¸ª CNN æ¥è®¡ç®—è¾“å‡ºç»´åº¦
        temp_cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=8, stride=4, padding=0),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),
            nn.ReLU(),
            nn.Flatten(),
        )
        with torch.no_grad():
            dummy_canvas = torch.zeros(1, 1, canvas_size, canvas_size)
            cnn_output_dim = temp_cnn(dummy_canvas).shape[1]
        
        # è®¡ç®—æ€»çš„ç‰¹å¾ç»´åº¦
        features_dim = cnn_output_dim + hidden_dim + hidden_dim
        
        # --- æ­¥éª¤ 2: ã€æ ¸å¿ƒä¿®æ­£ã€‘ç«‹å³è°ƒç”¨çˆ¶ç±»çš„ __init__ æ–¹æ³• ---
        # ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº† features_dimï¼Œå¯ä»¥å®‰å…¨åœ°è°ƒç”¨å®ƒäº†
        super().__init__(observation_space, features_dim)

        # --- æ­¥éª¤ 3: ç°åœ¨å¯ä»¥å®‰å…¨åœ°å°†æ¨¡å—èµ‹å€¼ç»™ self äº† ---
        self.canvas_size = canvas_size
        
        # å°†æˆ‘ä»¬ä¹‹å‰ä¸´æ—¶åˆ›å»ºçš„ cnn èµ‹ç»™ self.cnn
        # æˆ–è€…é‡æ–°åˆ›å»ºä¸€éï¼Œæ•ˆæœä¸€æ ·
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=8, stride=4, padding=0),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),
            nn.ReLU(),
            nn.Flatten(),
        )
        
        impedance_dim = observation_space["impedance"].shape[0]
        target_z_dim = observation_space["target_z"].shape[0]

        self.impedance_fc = nn.Linear(impedance_dim, hidden_dim)
        self.target_z_fc = nn.Linear(target_z_dim, hidden_dim)
        
        print("--- CustomCombinedExtractorForDQN Initialized ---")
        # ... (å…¶ä½™æ‰“å°ä¿¡æ¯)
        
    def forward(self, observations: dict) -> torch.Tensor:
        # forward æ–¹æ³•ä¿æŒä¸å˜
        # ...
        # æå–å„ä¸ªéƒ¨åˆ†çš„è§‚æµ‹
        impedance = observations["impedance"]
        target_z = observations["target_z"]
        decap_map = observations["decap_map"] # åŸå§‹å°ºå¯¸çš„åœ°å›¾, e.g., (N, 20, 15)

        # --- æ ¸å¿ƒé€»è¾‘ï¼šå°†ä¸åŒå°ºå¯¸çš„ decap_map ç»˜åˆ¶åˆ°å›ºå®šå¤§å°çš„ç”»å¸ƒä¸Š ---
        batch_size = decap_map.shape[0]
        device = decap_map.device
        
        canvas = torch.zeros(batch_size, 1, self.canvas_size, self.canvas_size, device=device)
        map_h, map_w = decap_map.shape[1], decap_map.shape[2]
        
        # å°†åŸå§‹åœ°å›¾å†…å®¹å¤åˆ¶åˆ°ç”»å¸ƒçš„å·¦ä¸Šè§’
        canvas[:, 0, :map_h, :map_w] = decap_map
        
        # --- ç‰¹å¾æå– ---
        canvas_features = self.cnn(canvas)
        impedance_features = F.relu(self.impedance_fc(impedance))
        target_z_features = F.relu(self.target_z_fc(target_z))
        
        # --- æ‹¼æ¥æ‰€æœ‰ç‰¹å¾ ---
        concatenated_features = torch.cat([canvas_features, impedance_features, target_z_features], dim=1)
        
        return concatenated_features

# maskable_dqn.py


from typing import Any, Dict, Optional, Tuple
from stable_baselines3 import DQN
from sb3_contrib.common.maskable.utils import get_action_masks, is_masking_supported


class MaskableDQN(DQN):
    """
    ä¸€ä¸ªæ”¯æŒåŠ¨ä½œæ©ç çš„ã€å®Œæ•´çš„è‡ªå®šä¹‰DQNç®—æ³•ã€‚
    å®ƒå€Ÿé‰´äº† sb3-contrib ä¸­ MaskablePPO çš„æ€æƒ³ï¼Œ
    åŒæ—¶åœ¨ predict (å†³ç­–) å’Œ train (å­¦ä¹ ) é˜¶æ®µåº”ç”¨æ©ç ã€‚
    """

    def __init__(self, *args, **kwargs):
        # åœ¨åˆ›å»ºæ—¶ï¼Œç¡®ä¿ replay_buffer_kwargs åŒ…å« handle_timeout_termination=True
        # è¿™ä¼šéšå¼åœ°è®© ReplayBuffer å¼€å§‹å­˜å‚¨ info å­—å…¸
        if "replay_buffer_kwargs" not in kwargs:
            kwargs["replay_buffer_kwargs"] = {}
        kwargs["replay_buffer_kwargs"]["handle_timeout_termination"] = True
        
        super().__init__(*args, **kwargs)

    def predict(
        self,
        observation: np.ndarray,
        state: Optional[Tuple[np.ndarray, ...]] = None,
        episode_start: Optional[np.ndarray] = None,
        deterministic: bool = False,
    ) -> Tuple[np.ndarray, Optional[Tuple[np.ndarray, ...]]]:
        """
        åœ¨é€‰æ‹©åŠ¨ä½œå‰åº”ç”¨åŠ¨ä½œæ©ç ã€‚
        (æ²¿ç”¨æˆ‘ä»¬ä¹‹å‰ç¨³å®šã€ç®€æ´çš„ç‰ˆæœ¬)
        """
        if not deterministic and np.random.rand() < self.exploration_rate:
            # æ¢ç´¢ï¼šä»æœ‰æ•ˆåŠ¨ä½œä¸­éšæœºé€‰æ‹©
            action_masks = get_action_masks(self.env)
            actions = []
            for mask in action_masks:
                valid_actions = np.where(mask)[0]
                if len(valid_actions) > 0:
                    actions.append(np.random.choice(valid_actions))
                else:
                    actions.append(self.action_space.sample()) # Fallback
            return np.array(actions), state
        else:
            # åˆ©ç”¨ï¼šä»æœ‰æ•ˆåŠ¨ä½œä¸­é€‰æ‹©Qå€¼æœ€é«˜çš„
            obs_tensor, _ = self.policy.obs_to_tensor(observation)
            with th.no_grad():
                q_values = self.policy.q_net(obs_tensor)

            action_masks = get_action_masks(self.env)
            mask_tensor = th.tensor(action_masks, device=self.device, dtype=th.float32)
            masked_q_values = q_values + (1.0 - mask_tensor) * -1e9
            
            action = th.argmax(masked_q_values, dim=1).cpu().numpy()
            return action, state

    def train(self, gradient_steps: int, batch_size: int = 100) -> None:
        # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼
        self.policy.set_training_mode(True)
        # æ›´æ–°å­¦ä¹ ç‡
        self._update_learning_rate(self.policy.optimizer)

        losses = []
        for _ in range(gradient_steps):
            # ä»ç»éªŒå›æ”¾æ± ä¸­é‡‡æ ·
            replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)

            with th.no_grad():
                # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘è®¡ç®—ç›®æ ‡Qå€¼æ—¶åº”ç”¨æ©ç  ---
                
                # 1. ä½¿ç”¨åœ¨çº¿ç½‘ç»œä¸º Double-DQN é€‰æ‹©ä¸‹ä¸€ä¸ªåŠ¨ä½œ
                next_q_values_online = self.policy.q_net(replay_data.next_observations)
                
                # 2. ä» info å­—å…¸ä¸­è·å– next_observations å¯¹åº”çš„åŠ¨ä½œæ©ç 
                # æˆ‘ä»¬éœ€è¦ä¸€ä¸ª'å…œåº•'çš„æ©ç ï¼Œä»¥é˜²æŸäº›æ ·æœ¬æ²¡æœ‰è¿™ä¸ªä¿¡æ¯
                default_mask = np.ones((1, self.action_space.n), dtype=np.float32)
                
                next_action_masks = np.array([
                    info.get("action_mask", default_mask) for info in replay_data.infos
                ]).squeeze() # .squeeze() to remove extra dimensions if any
                
                next_mask_tensor = th.tensor(next_action_masks, device=self.device, dtype=th.float32)

                # 3. å±è”½æ— æ•ˆåŠ¨ä½œçš„Qå€¼
                masked_next_q_values = next_q_values_online + (1.0 - next_mask_tensor) * -1e9

                # 4. ä»è¢«å±è”½çš„Qå€¼ä¸­é€‰æ‹©æœ€ä¼˜åŠ¨ä½œçš„ç´¢å¼•
                next_actions_indices = th.argmax(masked_next_q_values, dim=1).unsqueeze(-1)

                # 5. ä½¿ç”¨ç›®æ ‡ç½‘ç»œè·å–è¿™äº›æœ€ä¼˜åŠ¨ä½œçš„Qå€¼
                next_q_values_target = self.policy.q_net_target(replay_data.next_observations)
                target_q_from_next_state = next_q_values_target.gather(1, next_actions_indices)

                # 6. è®¡ç®—æœ€ç»ˆçš„ç›®æ ‡Qå€¼
                target_q = replay_data.rewards + (1 - replay_data.dones) * self.gamma * target_q_from_next_state

            # è·å–å½“å‰çŠ¶æ€-åŠ¨ä½œå¯¹çš„Qå€¼
            current_q_values = self.policy.q_net(replay_data.observations)
            current_q = current_q_values.gather(1, replay_data.actions)

            # è®¡ç®—æŸå¤±
            loss = F.smooth_l1_loss(current_q, target_q)
            losses.append(loss.item())

            # ä¼˜åŒ–æ­¥éª¤
            self.policy.optimizer.zero_grad()
            loss.backward()
            th.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)
            self.policy.optimizer.step()

        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        self._n_updates += gradient_steps
        if self._n_updates % self.target_update_interval == 0:
            self.policy.q_net_target.load_state_dict(self.policy.q_net.state_dict())

        # è®°å½•æ—¥å¿—
        self.logger.record("train/n_updates", self._n_updates, exclude="tensorboard")
        self.logger.record("train/loss", np.mean(losses))
class CircuitEnv(gym.Env):
    metadata = {'render_modes': ['console']}

    def __init__(self, ckt_file, result_file, render_mode=None):
        super(CircuitEnv, self).__init__()

        # ------------------ 1. åˆå§‹åŒ–ç¯å¢ƒå‚æ•° (ä¸æ‚¨åŸç‰ˆç›¸åŒ) ------------------
        with open(ckt_file, "r") as f:
            design = yaml.load(f.read(), Loader=yaml.FullLoader)
        with open(result_file, "r") as f:
            self.initial_result = yaml.load(f.read(), Loader=yaml.FullLoader)

        self.vdd = design["vdd"]
        self.target_impedance_value = 0.1 * self.vdd * self.vdd / design["chiplets"][0]["power"]
        
        self.base_ckt = build_ac_ckt(ckt_file, result_file)
        self.frequency_points = np.geomspace(0.1e9, 10e9, 100) # 100ä¸ªé¢‘ç‡ç‚¹
        
        self.interposer_w = design["interposer"]["w"]
        self.interposer_h = design["interposer"]["h"]
        self.initial_candidate_branch = [
            f"cd_{x}_{y}" for x in range(self.interposer_w) for y in range(self.interposer_h)
            if (x, y) not in self.initial_result["tsvs"]
        ]
        self.num_initial_candidates = len(self.initial_candidate_branch)

        # ------------------ 2. å®šä¹‰è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ (ä¸æ‚¨åŸç‰ˆç›¸åŒ) ------------------
        num_freq_points = len(self.frequency_points)
        self.observation_space = spaces.Dict({
            "impedance": spaces.Box(low=0, high=1, shape=(num_freq_points,), dtype=np.float64),
            "target_z": spaces.Box(low=0, high=1, shape=(num_freq_points,), dtype=np.float64),
            "decap_map": spaces.Box(low=0, high=1, shape=(self.interposer_w, self.interposer_h), dtype=np.float64)
        })
        self.action_space = spaces.Discrete(self.num_initial_candidates)
        
        # æ‰©å¤§é˜»æŠ—å€¼ï¼Œä¾¿äºå½’ä¸€åŒ–æ“ä½œ
        self.Z_MIN = 1e-4 
        self.Z_MAX = 0.3 # æˆ–è€…å¯ä»¥ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œæ¯”å¦‚ 0.1ï¼Œä»¥åº”å¯¹å¯èƒ½çš„å¼‚å¸¸å€¼
        self.Z_RANGE = self.Z_MAX - self.Z_MIN

        # ------------------ 3. å‡†å¤‡ä»¿çœŸæ‰€éœ€çš„é™æ€å‚æ•° (ä¸æ‚¨åŸç‰ˆç›¸åŒ) ------------------
        self._prepare_sim_tensors()
        self.render_mode = render_mode

        # ------------------ 4. åˆå§‹åŒ–å¥–åŠ±å‡½æ•°æ‰€éœ€çš„çŠ¶æ€å˜é‡ ------------------
        # åœ¨ reset() ä¸­ä¼šè¢«æ­£ç¡®èµ‹å€¼
        self.total_violation = 0.0

    # _prepare_sim_tensors, _get_impedances, _get_obs, action_masks, _get_info
    # è¿™äº›è¾…åŠ©å‡½æ•°ä¸æ‚¨çš„ç‰ˆæœ¬å®Œå…¨ç›¸åŒï¼Œè¿™é‡Œä¸ºäº†ç®€æ´çœç•¥ï¼Œç›´æ¥ä½¿ç”¨æ‚¨åŸæœ‰çš„å³å¯
    # ... (æ­¤å¤„çœç•¥æ‚¨å·²æœ‰çš„ _prepare_sim_tensors, _get_impedances, _get_obs, action_masks, _get_info å‡½æ•°)
    def _prepare_sim_tensors(self):
        observe_branch = ["id"]
        typ, u, v, val, index = self.base_ckt.prepare_sim("0", observe_branch + self.initial_candidate_branch)
        self.typ, self.u, self.v = typ, u, v
        self.g_index, self.r_index, self.l_index, self.v_index = [torch.tensor([], dtype=torch.long)] * 4
        self.c_index_map = index[len(observe_branch):]
        self.i_index = index[:len(observe_branch)]
        (self.all_exc_index,) = torch.where((typ == BranchType.I) | (typ == BranchType.V))
        self.g_value, self.r_value, self.l_value = [torch.tensor([], dtype=torch.float64)] * 3
        self.initial_c_base_value = val[self.c_index_map]
        self.all_exc_value = val[self.all_exc_index]
        self.sims = [AcSimulationPardiso(typ, u, v, val, freq) for freq in self.frequency_points]

    def _get_impedances(self):
        zs = []
        c_value_tensor = torch.zeros_like(self.initial_c_base_value)
        if self.placed_capacitor_indices:
            placed_indices_tensor = torch.tensor(self.placed_capacitor_indices)
            c_value_tensor[placed_indices_tensor] = self.initial_c_base_value[placed_indices_tensor]
        c_index_tensor = self.c_index_map
        for freq, sim in zip(self.frequency_points, self.sims):
            sim.alter(c_index_tensor, c_value_tensor)
            sim.factorize()
            sim.solve()
            i_voltage = sim.branch_voltage(self.i_index)
            zs.append(i_voltage)
        return torch.cat(zs).abs().detach().numpy()

    def _get_obs(self):
        impedances_np = self._get_impedances()
        decap_map = np.zeros((self.interposer_w, self.interposer_h), dtype=np.float64)
        if self.placed_capacitor_indices:
            for action_index in self.placed_capacitor_indices:
                info = self.initial_candidate_branch[action_index]
                match = re.search(r"cd_(\d+)_(\d+)", info)
                if match:
                    x, y = int(match.group(1)), int(match.group(2))
                    decap_map[x, y] = 1.0
        return {"impedance": impedances_np, "target_z": np.full_like(impedances_np, self.target_impedance_value), "decap_map": decap_map}
        
        # ## å½’ä¸€åŒ–æ“ä½œ
        # # 1. è·å–åŸå§‹çš„ã€æœªå½’ä¸€åŒ–çš„é˜»æŠ—å€¼
        # impedances_np_raw = self._get_impedances()
        
        # # 2. ã€æ–°çš„å½’ä¸€åŒ–æ–¹æ³•ã€‘ Min-Max Scaling
        # # å…¬å¼: (X - min) / (max - min)
        # impedances_scaled = (impedances_np_raw - self.Z_MIN) / self.Z_RANGE
        
        # # å¯¹ç›®æ ‡å€¼ä¹ŸåšåŒæ ·çš„å¤„ç†
        # target_z_raw = np.full_like(impedances_np_raw, self.target_impedance_value)
        # target_z_scaled = (target_z_raw - self.Z_MIN) / self.Z_RANGE

        # # 3. è£å‰ªä»¥ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
        # # è¿™ä¸€æ­¥ä»ç„¶éå¸¸é‡è¦ï¼Œå¯ä»¥å¤„ç†æ‰ä»»ä½•è¶…å‡ºä½ é¢„è®¾èŒƒå›´çš„æ„å¤–å€¼
        # impedances_normalized = np.clip(impedances_scaled, 0, 1)
        # target_z_normalized = np.clip(target_z_scaled, 0, 1)

        # # ... (decap_map éƒ¨åˆ†ä¸å˜) ...
        # decap_map = np.zeros((self.interposer_w, self.interposer_h), dtype=np.float64)
        # if self.placed_capacitor_indices:
        #     for action_index in self.placed_capacitor_indices:
        #         info = self.initial_candidate_branch[action_index]
        #         match = re.search(r"cd_(\d+)_(\d+)", info)
        #         if match:
        #             x, y = int(match.group(1)), int(match.group(2))
        #             decap_map[x, y] = 1.0
        # # 5. è¿”å›å½’ä¸€åŒ–åçš„è§‚æµ‹å­—å…¸
        # return {
        #     "impedance": impedances_normalized, 
        #     "target_z": target_z_normalized, 
        #     "decap_map": decap_map
        # }

    def action_masks(self) -> np.ndarray:
        mask = np.ones(self.num_initial_candidates, dtype=bool)
        if self.placed_capacitor_indices:
            mask[self.placed_capacitor_indices] = False
        return mask

    def _get_info(self):
        return {"action_mask": self.action_masks()}


    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        # é‡ç½®çŠ¶æ€
        self.placed_capacitor_indices = []
        self.current_step = 0
        
        # è·å–åˆå§‹è§‚æµ‹
        observation = self._get_obs()
        
        # ã€ä¿®æ”¹ã€‘è®¡ç®—åˆå§‹çš„æ€»è¿è§„é‡
        impedances = observation["impedance"]
        violation_array = np.maximum(impedances - self.target_impedance_value, 0)
        self.total_violation = np.sum(violation_array)
        
        info = self._get_info()
        
        if self.render_mode == "console":
            self.render(observation, 0) # åˆå§‹å¥–åŠ±ä¸º0

        return observation, info
    
    def step(self, action):
    # 1. ã€æ ¸å¿ƒä¿®æ”¹ã€‘åœ¨æ‰§è¡ŒåŠ¨ä½œå‰ï¼Œè®°å½•æ—§çš„è¾¾æ ‡ç‚¹æ•°
        if action in self.placed_capacitor_indices:
            print(f"ğŸ”¥ğŸ”¥ğŸ”¥ æ”¾ç½®å¤±è´¥! ç”µå®¹ä½ç½®å ç”¨ã€‚")
            return self._get_obs(), 0, True, True, self._get_info()
        old_obs = self._get_obs()
        old_impedances = old_obs["impedance"]
        old_points_below_target = np.sum(old_impedances <= self.target_impedance_value)
        
        # 2. æ‰§è¡ŒåŠ¨ä½œ
        self.placed_capacitor_indices.append(action)
        self.current_step += 1

        # 3. è·å–æ–°çš„è§‚æµ‹å€¼
        observation = self._get_obs()
        new_impedances = observation["impedance"]
        new_points_below_target = np.sum(new_impedances <= self.target_impedance_value)

        # 4. ã€æ ¸å¿ƒä¿®æ”¹ã€‘è®¡ç®—æ–°çš„å¥–åŠ±
        # 4.1 ä¸»è¦å¥–åŠ±ï¼šåŸºäºè¾¾æ ‡ç‚¹æ•°çš„å¢åŠ é‡
        improvement_reward = (new_points_below_target - old_points_below_target)
        
        # æ”¾å¤§è¿™ä¸ªä¿¡å·ï¼Œä½¿å…¶æ¯”è¡ŒåŠ¨æˆæœ¬æ›´é‡è¦
        # ä¾‹å¦‚ï¼Œæ¯å¤šä¸€ä¸ªç‚¹è¾¾æ ‡ï¼Œå°±å¥–åŠ± 5 åˆ†
        reward = improvement_reward * 5.0
        
        # 4.2 è¡ŒåŠ¨æˆæœ¬ï¼šæ¯ä¸€æ­¥éƒ½ç»™äºˆä¸€ä¸ªå°çš„è´Ÿå¥–åŠ±
        action_cost = -2 # è¿™ä¸ªå€¼æ˜¯è¶…å‚æ•°ï¼Œå¯ä»¥è°ƒæ•´
        reward += action_cost

        # 5. åˆ¤æ–­å›åˆæ˜¯å¦ç»“æŸ
        # 5.1 æˆåŠŸç»ˆæ­¢ (Terminated): æ‰€æœ‰é¢‘ç‡ç‚¹éƒ½è¾¾æ ‡
        terminated = bool(new_points_below_target == len(self.frequency_points))
        
        # 5.2 å¤±è´¥æˆªæ–­ (Truncated): æ‰€æœ‰å¯ç”¨ä½ç½®éƒ½å·²æ”¾ç½®ç”µå®¹
        truncated = (len(self.placed_capacitor_indices) == self.num_initial_candidates)
        
        # 6. ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä¸ºå›åˆç»“æŸæ·»åŠ æœ€ç»ˆå¥–åŠ±æˆ–æƒ©ç½š
        if terminated:
            final_reward = 100.0
            efficiency_bonus = (self.num_initial_candidates - len(self.placed_capacitor_indices)) * 0.5
            final_reward += efficiency_bonus
            
            reward += final_reward
            print(f"ğŸ‰ğŸ‰ğŸ‰ æ”¾ç½®æˆåŠŸ! ä½¿ç”¨ç”µå®¹æ•°é‡: {len(self.placed_capacitor_indices)}, è·å¾—æ•ˆç‡å¥–åŠ±: {efficiency_bonus:.2f}")
            # reward += 200.0
            # print(f"ğŸ‰ğŸ‰ğŸ‰ æ”¾ç½®æˆåŠŸ! ä½¿ç”¨ç”µå®¹æ•°é‡: {len(self.placed_capacitor_indices)}")

        elif truncated and not terminated:
            reward -= 100 # ç”¨å°½æ‰€æœ‰ç”µå®¹ä»æœªæˆåŠŸï¼Œç»™äºˆå·¨å¤§çš„æƒ©ç½š
            print(f"ğŸ”¥ğŸ”¥ğŸ”¥ æ”¾ç½®å¤±è´¥! æ‰€æœ‰å¯ç”¨ä½ç½®å·²ç”¨å°½ã€‚")

        # 7. è·å–ä¿¡æ¯ï¼ˆåŒ…å«æ›´æ–°åçš„åŠ¨ä½œæ©ç ï¼‰
        info = self._get_info()
        final_info = {}
        for i, done in enumerate(np.atleast_1d(terminated or truncated)):
            if done:
                # å½“å›åˆç»“æŸæ—¶ï¼Œ"final_info" ä¸­åº”è¯¥åŒ…å«è¿™ä¸ªå›åˆçš„ä¿¡æ¯
                final_info[i] = info

        if self.render_mode == "console":
            self.render(observation, reward)
            
        return observation, reward, terminated, truncated, info


    # def step(self, action):
    #     # 1. æ‰§è¡ŒåŠ¨ä½œ: å°†é€‰æ‹©çš„ç”µå®¹ä½ç½®è®°å½•ä¸‹æ¥
    #     #    æ³¨æ„ï¼šæˆ‘ä»¬ä¸å†éœ€è¦æ£€æŸ¥ action æ˜¯å¦å·²è¢«æ”¾ç½®ï¼Œå› ä¸º MaskablePPO ä¼šå¤„ç†è¿™ä¸ªé—®é¢˜ã€‚
    #     self.placed_capacitor_indices.append(action)
    #     self.current_step += 1

    #     # 2. è·å–æ–°çš„è§‚æµ‹å€¼
    #     observation = self._get_obs()
    #     new_impedances = observation["impedance"]

    #     # 3. ã€æ ¸å¿ƒä¿®æ”¹ã€‘è®¡ç®—æ–°çš„å¥–åŠ±
    #     # 3.1 è®¡ç®—æ–°çš„æ€»è¿è§„é‡
    #     new_violation_array = np.maximum(new_impedances - self.target_impedance_value, 0)
    #     new_total_violation = np.sum(new_violation_array)

    #     # 3.2 è®¡ç®—å¥–åŠ± = è¿è§„é‡çš„å‡å°‘é‡ - è¡ŒåŠ¨æˆæœ¬
    #     # è¿è§„é‡å‡å°‘å¾—è¶Šå¤šï¼Œè¿™ä¸ªå€¼å°±è¶Šå¤§ï¼Œå¥–åŠ±ä¹Ÿè¶Šé«˜
    #     violation_reduction = self.total_violation - new_total_violation
        
    #     # å°†å‡å°‘é‡æ”¾å¤§ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæ›´å¼ºçš„å­¦ä¹ ä¿¡å·
    #     reward = violation_reduction * 10.0
        
    #     # å¢åŠ ä¸€ä¸ªå°çš„è´Ÿå¥–åŠ±ä½œä¸ºæ”¾ç½®ç”µå®¹çš„â€œæˆæœ¬â€ï¼Œé¼“åŠ±æ™ºèƒ½ä½“ä½¿ç”¨æ›´å°‘çš„ç”µå®¹
    #     reward -= 0.5  # è¿™ä¸ªå€¼æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå¯ä»¥è°ƒæ•´

    #     # 3.3 æ›´æ–°ç¯å¢ƒçŠ¶æ€ï¼Œä¸ºä¸‹ä¸€æ­¥åšå‡†å¤‡
    #     self.total_violation = new_total_violation

    #     # 4. åˆ¤æ–­å›åˆæ˜¯å¦ç»“æŸ
    #     # 4.1 æˆåŠŸç»ˆæ­¢ (Terminated): å½“æ€»è¿è§„é‡å°äºä¸€ä¸ªæå°å€¼æ—¶ï¼Œè®¤ä¸ºä»»åŠ¡æˆåŠŸ
    #     terminated = bool(self.total_violation < 1e-6)

    #     # 4.2 å¤±è´¥æˆªæ–­ (Truncated): å½“æ‰€æœ‰å¯ç”¨ä½ç½®éƒ½å·²æ”¾ç½®ç”µå®¹
    #     truncated = (len(self.placed_capacitor_indices) == self.num_initial_candidates)

    #     # 5. ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä¸ºå›åˆç»“æŸæ·»åŠ æœ€ç»ˆå¥–åŠ±æˆ–æƒ©ç½š
    #     if terminated:
    #         reward += 200  # æˆåŠŸå®Œæˆä»»åŠ¡ï¼Œç»™äºˆå·¨å¤§çš„é¢å¤–å¥–åŠ±
    #         print(f"ğŸ‰ğŸ‰ğŸ‰ æ”¾ç½®æˆåŠŸ! ä½¿ç”¨ç”µå®¹æ•°é‡: {len(self.placed_capacitor_indices)}")
            
    #     elif truncated and not terminated:
    #         reward -= 100 # ç”¨å°½æ‰€æœ‰ç”µå®¹ä»æœªæˆåŠŸï¼Œç»™äºˆå·¨å¤§çš„æƒ©ç½š
    #         print(f"ğŸ”¥ğŸ”¥ğŸ”¥ æ”¾ç½®å¤±è´¥! æ‰€æœ‰å¯ç”¨ä½ç½®å·²ç”¨å°½ã€‚")

    #     # 6. è·å–ä¿¡æ¯ï¼ˆåŒ…å«æ›´æ–°åçš„åŠ¨ä½œæ©ç ï¼‰
    #     info = self._get_info()

    #     if self.render_mode == "console":
    #         self.render(observation, reward)
            
    #     return observation, reward, terminated, truncated, info

    def render(self, observation, reward, mode='console'):
        # (ä¸æ‚¨åŸç‰ˆç›¸åŒ)
        if mode == 'console':
            impedances_part = observation["impedance"]
            peak_impedance = np.max(impedances_part)
            points_below_target = np.sum(impedances_part <= self.target_impedance_value)
            self.total_violation = np.sum(np.maximum(impedances_part - self.target_impedance_value, 0))


            print(
                f"Step: {self.current_step}, "
                # f"Placed Caps: {len(self.placed_capacitor_indices)}, "
                f"Placed Caps: {self.placed_capacitor_indices}, "
                f"Reward: {reward:+.4f}, "
                f"Total Violation: {self.total_violation:.4f}, "
                f"Peak Impedance: {peak_impedance:.4f}, "
                f"Points Below Target: {points_below_target}/{len(self.frequency_points)}"
            )
 